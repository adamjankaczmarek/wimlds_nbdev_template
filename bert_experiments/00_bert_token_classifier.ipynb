{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bert_experiments.bert_token_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Token Classifier - PyTorch-Lightning Module\n",
    "\n",
    "> A PyTorch-Lightning implementation of a Bert model for Token Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import argparse\n",
    "import torch\n",
    "import joblib\n",
    "import lineflow as lf\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from transformers import BertForTokenClassification, BertTokenizer, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BertTokenClassifier(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    BertTokenClassifier module for training Bert models for Token Classification Problem\n",
    "    eg. Named Entity Recognition\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BertTokenClassifier, self).__init__()\n",
    "        self.config = config \n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.config[\"model\"][\"bert\"], do_lower_case=config[\"data\"][\"lower_case\"])\n",
    "        self.model = BertForTokenClassification.from_pretrained(self.config[\"model\"][\"bert\"], num_labels=2, output_attentions=False, output_hidden_states=False)\n",
    "    \n",
    "    # Execute\n",
    "    \n",
    "    def forward(batch):\n",
    "        return self.model(**batch)\n",
    "    \n",
    "    # Optimizers\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=float(self.config[\"model\"]['lr']))\n",
    "        #total_steps =  * config[\"model\"][\"epochs\"]\n",
    "        #scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "        #return [optimizer], [scheduler]\n",
    "        return optimizer\n",
    "        \n",
    "    # Train/Validate/Test\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _ = self.model(**batch)\n",
    "        tqdm_dict = {\"train_loss\": loss}\n",
    "        output = {\"loss\": loss, \"progress_bar\": tqdm_dict,\"log\": tqdm_dict}\n",
    "        return output\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, logits = self.model(**batch)\n",
    "        labels_hat = torch.argmax(logits, dim=-1)\n",
    "        correct_count = torch.sum((batch['labels'] == labels_hat) * batch['attention_mask'])\n",
    "\n",
    "        if self.on_gpu:\n",
    "            correct_count = correct_count.cuda(loss.device.index)\n",
    "\n",
    "        return {\"val_loss\": loss, \"correct_count\": correct_count, \"batch_size\": len(batch['labels']), \"total_labels\": batch['attention_mask'].sum()}\n",
    "        \n",
    "    def validation_end(self, outputs):\n",
    "        val_acc = sum([out[\"correct_count\"] for out in outputs]).float() / sum(out[\"total_labels\"] for out in outputs)\n",
    "        val_loss = sum([out[\"val_loss\"] for out in outputs]) / len(outputs)\n",
    "        tqdm_dict = {\"val_loss\": val_loss, \"val_acc\": val_acc}\n",
    "        return {\"progress_bar\": tqdm_dict, \"log\": tqdm_dict, \"val_loss\": val_loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, logits = self.model(**batch)\n",
    "        labels_hat = torch.argmax(logits, dim=-1)\n",
    "        # print(batch['labels'])\n",
    "        # print(labels_hat)\n",
    "        correct_count = torch.sum((batch['labels'] == labels_hat) * batch['attention_mask'])\n",
    "\n",
    "        if self.on_gpu:\n",
    "            correct_count = correct_count.cuda(loss.device.index)\n",
    "\n",
    "        return {\"test_loss\": loss, \"correct_count\": correct_count, \"batch_size\": len(batch['labels']), \"total_labels\": batch['attention_mask'].sum()}\n",
    "\n",
    "    def test_end(self, outputs):\n",
    "        test_acc = sum([out[\"correct_count\"] for out in outputs]).float() / sum(out[\"total_labels\"] for out in outputs)\n",
    "        test_loss = sum([out[\"test_loss\"] for out in outputs]) / len(outputs)\n",
    "        tqdm_dict = {\"test_loss\": test_loss, \"test_acc\": test_acc}\n",
    "        return {\"progress_bar\": tqdm_dict, \"log\": tqdm_dict}\n",
    "        \n",
    "    \n",
    "    # Dataloaders\n",
    "    \n",
    "    def _preprocessor(self, instance):\n",
    "        tokens = [word if not word.startswith(\"*\") else word[1:] for word in instance.split(\" \")]\n",
    "        labels = [int(not word.startswith(\"*\")) for word in instance.split(\" \")]\n",
    "        tokenized_tokens = list(map(self.tokenizer.tokenize, tokens))\n",
    "        tokenized_labels = [[l] * len(tt) for l, tt in zip(labels, tokenized_tokens)]\n",
    "        flat_tokens = [t for tt in tokenized_tokens for t in tt]\n",
    "        flat_labels = [l for ll in tokenized_labels for l in ll]\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\" \".join(tokens), add_special_tokens=True, max_length=self.config[\"data\"][\"max_len\"])\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "        labels = [0] + flat_labels[:self.config[\"data\"][\"max_len\"]-2] + [0]\n",
    "       \n",
    "        convert_ids = self.tokenizer.convert_tokens_to_ids(flat_tokens)\n",
    "        assert input_ids[1:-1] == convert_ids[:len(input_ids)-2]\n",
    "        assert len(input_ids) == len(labels)\n",
    "\n",
    "        original_input_ids_len = len(input_ids)\n",
    "        padding_length = self.config[\"data\"][\"max_len\"] - original_input_ids_len\n",
    "        input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n",
    "        labels = labels + [0] * padding_length\n",
    "        token_type_ids = token_type_ids + [self.tokenizer.pad_token_id] * padding_length\n",
    "        attention_mask = [1] * original_input_ids_len + [0] * padding_length\n",
    "        \n",
    "        return {\n",
    "            \"labels\": torch.tensor(labels).long(),  # Label*s* - vide training_step\n",
    "            \"input_ids\": torch.tensor(input_ids),\n",
    "            \"attention_mask\": torch.tensor(attention_mask),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids)\n",
    "        }\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train = lf.TextDataset(self.config[\"data\"][\"train_file\"]).map(self._preprocessor)\n",
    "        return DataLoader(train, sampler=RandomSampler(train), batch_size=self.config[\"model\"][\"batch_size\"], num_workers=32)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        # val = lf.Dataset(lf.TextDataset(self.config[\"data\"][\"val_file\"]).take(100)).map(self._preprocessor).save(self.config[\"data\"][\"val_cache\"])\n",
    "        val = lf.TextDataset(self.config[\"data\"][\"val_file\"]).map(self._preprocessor)\n",
    "        return DataLoader(val, sampler=SequentialSampler(val), batch_size=self.config[\"model\"][\"batch_size\"], num_workers=32)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test = lf.TextDataset(self.config[\"data\"][\"test_file\"]).map(self._preprocessor)\n",
    "        return DataLoader(test, sampler=SequentialSampler(test), batch_size=self.config[\"model\"][\"batch_size\"], num_workers=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "      \"bert\": 'bert-base-multilingual-cased'\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"lower_case\": True,\n",
    "        \"max_len\": 256\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00df0e1ebee4e96ae8b3f2c60cb9ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=995526.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b711241853694bce8062195c137b590a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2172336378f4bb382b1d88916b0eca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=714314041.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "btc_lower_case = BertTokenClassifier(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower case model is insensitive to letter cases :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ala_1 = btc_lower_case._preprocessor(\"Ala ma kota\")\n",
    "ala_2 = btc_lower_case._preprocessor(\"ala ma KoTa\")\n",
    "\n",
    "assert ala_1[\"input_ids\"].equal(ala_2[\"input_ids\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
