---

title: Bert Token Classifier - PyTorch-Lightning Module


keywords: fastai
sidebar: home_sidebar

summary: "A PyTorch-Lightning implementation of a Bert model for Token Classification Problem"
description: "A PyTorch-Lightning implementation of a Bert model for Token Classification Problem"
nb_path: "bert_experiments/00_bert_token_classifier.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: bert_experiments/00_bert_token_classifier.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertTokenClassifier" class="doc_header"><code>class</code> <code>BertTokenClassifier</code><a href="https://github.com/adamjankaczmarek/wimlds_nbdev_template/tree/master/wimlds_nbdev_template/bert_experiments/bert_token_classifier.py#L21" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertTokenClassifier</code>(<strong><code>config</code></strong>) :: <code>LightningModule</code></p>
</blockquote>
<p>BertTokenClassifier module for training Bert models for Token Classification Problem
eg. Named Entity Recognition</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h1>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">&quot;bert&quot;</span><span class="p">:</span> <span class="s1">&#39;bert-base-multilingual-cased&#39;</span>
    <span class="p">},</span>
    <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;lower_case&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;max_len&quot;</span><span class="p">:</span> <span class="mi">256</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">btc_lower_case</span> <span class="o">=</span> <span class="n">BertTokenClassifier</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>


</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;]
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Lower-case-model-is-insensitive-to-letter-cases-:)">Lower case model is insensitive to letter cases :)<a class="anchor-link" href="#Lower-case-model-is-insensitive-to-letter-cases-:)"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ala_1</span> <span class="o">=</span> <span class="n">btc_lower_case</span><span class="o">.</span><span class="n">_preprocessor</span><span class="p">(</span><span class="s2">&quot;Ala ma kota&quot;</span><span class="p">)</span>
<span class="n">ala_2</span> <span class="o">=</span> <span class="n">btc_lower_case</span><span class="o">.</span><span class="n">_preprocessor</span><span class="p">(</span><span class="s2">&quot;ala ma KoTa&quot;</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">ala_1</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">ala_2</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

